{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/home/pranav/anaconda3/envs/env-TF2/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "from fastai import *\n",
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.feature_extraction.text as sklearn_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "??URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://files.fast.ai/data/examples/imdb_sample'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URLs.IMDB_SAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/pranav/.fastai/data/imdb_sample')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.IMDB_SAMPLE)\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>Un-bleeping-believable! Meg Ryan doesn't even ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>This is a extremely well-made film. The acting...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>Every once in a long while a movie will come a...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>Name just says it all. I watched this movie wi...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>This movie succeeds at being one of the most u...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text  is_valid\n",
       "0  negative  Un-bleeping-believable! Meg Ryan doesn't even ...     False\n",
       "1  positive  This is a extremely well-made film. The acting...     False\n",
       "2  negative  Every once in a long while a movie will come a...     False\n",
       "3  positive  Name just says it all. I watched this movie wi...     False\n",
       "4  negative  This movie succeeds at being one of the most u...     False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path/'texts.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "movie_reviews = (TextList.from_csv(path,'texts.csv', cols= 'text').split_from_df(col=2).label_from_df(cols=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelList (200 items)\n",
       "x: TextList\n",
       "xxbos xxmaj this very funny xxmaj british comedy shows what might happen if a section of xxmaj london , in this case xxmaj xxunk , were to xxunk itself independent from the rest of the xxup uk and its laws , xxunk & post - war xxunk . xxmaj merry xxunk is what would happen . \n",
       " \n",
       "  xxmaj the explosion of a wartime bomb leads to the xxunk of ancient xxunk which show that xxmaj xxunk was xxunk to the xxmaj xxunk of xxmaj xxunk xxunk ago , a small historical xxunk long since forgotten . xxmaj to the new xxmaj xxunk , however , this is an unexpected opportunity to live as they please , free from any xxunk from xxmaj xxunk . \n",
       " \n",
       "  xxmaj stanley xxmaj xxunk is excellent as the minor city xxunk who suddenly finds himself leading one of the world 's xxunk xxunk . xxmaj xxunk xxmaj margaret xxmaj xxunk is a delight as the history professor who sides with xxmaj xxunk . xxmaj others in the stand - out cast include xxmaj xxunk xxmaj xxunk , xxmaj paul xxmaj xxunk , xxmaj xxunk xxmaj xxunk , xxmaj xxunk xxmaj xxunk & xxmaj sir xxmaj michael xxmaj xxunk . \n",
       " \n",
       "  xxmaj welcome to xxmaj xxunk !,xxbos i saw this movie once as a kid on the late - late show and fell in love with it . \n",
       " \n",
       "  xxmaj it took 30 + years , but i recently did find it on xxup dvd - it was n't cheap , either - in a xxunk that xxunk in war movies . xxmaj we watched it last night for the first time . xxmaj the audio was good , however it was grainy and had the trailers between xxunk . xxmaj even so , it was better than i remembered it . i was also impressed at how true it was to the play . \n",
       " \n",
       "  xxmaj the xxunk is around here xxunk . xxmaj if you 're xxunk in finding it , fire me a xxunk and i 'll see if i can get you the xxunk . xxunk,xxbos xxmaj this is , in my opinion , a very good film , especially for xxmaj michael xxmaj jackson lovers . xxmaj it contains a message on drugs , stunning special effects , and an awesome music video . \n",
       " \n",
       "  xxmaj the main film is xxunk around the song and music video ' xxmaj smooth xxmaj criminal . ' xxmaj unlike the four - minute music video , it is normal speed and , in my opinion , much xxunk to watch . \n",
       " \n",
       "  xxmaj the plot is rather weird , however . xxmaj michael xxmaj jackson plays a xxunk ' gangster ' that , when he sees a shooting star , he xxunk into a piece of xxunk . xxmaj throughout the film , he xxunk into a race car , a giant robot , and a space ship . \n",
       " \n",
       "  xxmaj the robot scene in particular is a bit drawn out and strange . i found it a little out - of - whack compared to the rest of the film . \n",
       " \n",
       "  a child is kidnapped , xxmaj michael tries to save her , is tortured and beaten , and suddenly turns into a giant robot that blows up all the bad guys . a little weird ? xxmaj yeah . \n",
       " \n",
       "  xxmaj but besides the bizarre robot scene , it 's a very good movie , and any xxmaj michael xxmaj jackson fan will enjoy both the xxmaj smooth xxmaj criminal music video and the movie .,xxbos xxmaj in xxmaj iran , women are not xxunk to attend men 's sporting events , apparently to \" xxunk \" them from all the xxunk and foul language they might hear xxunk from the male fans ( so since men ca n't xxunk or xxunk themselves , women are forced to suffer . xxmaj go figure . ) . \" xxmaj xxunk \" tells the tale of a half dozen or so young women who , dressed like men , attempt to xxunk into the high - xxunk match between xxmaj iran and xxmaj xxunk that , in xxunk , qualified xxmaj iran to go to the xxmaj world xxmaj cup ( the movie was actually filmed in large part during that game ) . \n",
       " \n",
       "  \" xxmaj xxunk \" is a xxunk - of - life comedy that will remind you of all those great xxunk films ( \" xxmaj the xxmaj shop on xxmaj main xxmaj street , \" \" xxmaj loves of a xxmaj blonde , \" \" xxmaj closely xxmaj watched xxmaj trains \" etc . ) that xxunk out of xxmaj communist xxmaj xxunk as part of the \" xxmaj xxunk xxmaj xxunk \" in the mid xxunk 's . xxmaj as with many of those works , \" xxmaj xxunk \" is more concerned with xxunk life than with xxunk any kind of xxunk contrived fictional narrative . xxmaj indeed , it is the simplicity of the xxunk and the xxunk of the style that make the movie so effective . \n",
       " \n",
       "  xxmaj once their xxunk is discovered , the girls are xxunk into a small xxunk right outside the xxunk where they can hear the xxunk xxunk xxunk from the game inside . xxmaj stuck where they are , all they can do is xxunk with the security guards to let them go in , guards who are basically xxunk , good - xxunk xxunk who are compelled to do their duty as a part of their xxunk military service . xxmaj even most of the men going into the xxunk do n't seem particularly xxunk at the thought of these women being allowed in . xxmaj still the prohibition xxunk . xxmaj yet , how can one not be impressed by the very real courage and xxunk displayed by these women as they go up against a system that continues to xxunk such a xxunk xxunk and xxunk xxunk ? xxmaj and , yet , the purpose of these women is not to xxunk behind a cause or to make a \" point . \" xxmaj they are simply obsessed fans with a burning desire to watch a soccer game and , like all the men in the country , xxunk on their team . \n",
       " \n",
       "  xxmaj it 's hard to tell just how much of the dialogue is scripted and how much of it is xxunk , but , in either case , the actors , with their xxunk xxunk faces , do a magnificent job making each moment seem utterly real and convincing . xxmaj xxunk xxmaj xxunk - xxunk and xxmaj xxunk xxmaj xxunk are notable xxunk in a xxunk excellent cast . xxmaj the structure of the film is also very loose and xxunk , as writer / director xxmaj xxunk xxmaj xxunk and co - writer xxmaj xxunk xxmaj xxunk focus for a few brief moments on one or two of the characters , then move xxunk and xxunk onto others . xxmaj with this documentary - type approach , we come to feel as if we are xxunk an actual event xxunk in \" real time . \" xxmaj very often , it 's quite easy for us to forget we 're actually watching a movie . \n",
       " \n",
       "  xxmaj it was a very smart move on the part of the filmmakers to include so much good - xxunk humor in the film ( it 's what the xxmaj xxunk filmmakers did as well ) , the better to point up the utter absurdity of the situation and xxunk the appeal of the film for audiences both domestic and foreign . \" xxmaj xxunk \" is obviously a cry for justice , but it is one that is made all the more effective by its xxunk to make of its story a heavy - breathing tragedy . xxmaj instead , it realizes that nothing breaks down social xxunk quite as xxunk as humor and an appeal to the audience 's common humanity . xxmaj and is n't that what true art is supposed to be all about ? xxmaj in its own quiet , xxunk way , \" xxmaj xxunk \" is one of the great , under - appreciated xxunk of xxunk .,xxbos \" xxmaj in xxmaj xxunk xxunk , the xxmaj university of xxmaj xxunk xxunk to xxunk xxmaj xxunk xxmaj national xxmaj xxunk , with an xxunk of xxmaj xxunk xxunk offering to xxunk the research . xxmaj xxunk xxunk became the first \" national \" xxunk . xxmaj it did not , however , remain at its original location in the xxmaj xxunk forest . xxmaj in xxunk , it moved xxunk west from the \" xxmaj xxunk xxmaj city \" to a new site on xxmaj xxunk xxunk . xxmaj when xxmaj xxunk xxmaj xxunk visited xxmaj xxunk 's director , xxmaj walter xxmaj xxunk , in xxunk , he asked him what kind of xxunk was to be built at the new site . xxmaj when xxmaj xxunk described a heavy - water xxunk xxunk at one - xxunk the power of the xxmaj xxunk xxmaj xxunk xxmaj xxunk under design at xxmaj xxunk xxmaj xxunk , xxmaj xxunk xxunk it would be xxunk if xxmaj xxunk took the xxmaj xxunk xxmaj xxunk design and xxunk the xxmaj xxunk xxmaj xxunk xxmaj xxunk at one - xxunk capacity . xxmaj the joke proved unintentionally xxunk . \" \n",
       " \n",
       "  xxmaj the xxup xxunk plant used xxunk to separate the xxunk in thousands of tall xxunk . xxmaj it was built next to the xxup xxunk power plant , which provided the necessary steam . xxmaj much less xxunk than xxup xxunk , the xxup xxunk plant was torn down after the war . \n",
       " \n",
       "  xxmaj concerned that the xxmaj xxunk xxmaj energy xxmaj xxunk research program might become too xxunk , xxmaj xxunk xxunk a xxunk of industrial xxunk , and during a xxmaj xxunk visit to xxmaj xxunk xxmaj xxunk , he xxunk with xxmaj clark xxmaj center , manager of xxmaj xxunk & xxmaj xxunk , a xxunk of xxmaj union xxmaj xxunk xxmaj corporation at xxmaj xxunk xxmaj xxunk , the possibility of the company xxunk xxunk of the xxmaj xxunk . \n",
       " \n",
       "  xxmaj prince xxmaj henry ( of xxmaj xxunk ) xxmaj xxunk in xxmaj washington and xxmaj visiting the xxmaj german xxmaj xxunk ( xxunk ) . xxmaj xxunk , with xxmaj prince xxmaj henry of xxmaj xxunk according to the xxunk of science and its xxunk their were already concerns with the xxunk of new science with military xxunk . xxmaj the xxmaj xxunk ( xxunk / xxup ii ) , \" xxmaj xxunk xxmaj xxunk 's splendid xxunk at the xxunk xxmaj st. xxmaj xxunk , xxmaj new xxmaj york . xxmaj taken at the exact moment of xxmaj prince xxmaj henry 's xxunk , and the raising of the xxunk standard . \" xxmaj if xxmaj xxunk knew of these necessary xxunk to xxunk xxunk then what was the xxunk of the xxunk xxup xxunk and xxup wwii . xxmaj the quality of xxunk control i xxunk ? \n",
       " \n",
       "  xxmaj thus , did the xxunk of xxmaj xxunk xxmaj xxunk xxunk for a military mission , or a business plan , based on the security xxunk of xxmaj xxunk xxunk ? xxmaj because supposedly their were no survivors , and the ones who were caught in xxmaj europe ordered to be executed . xxmaj of the xxunk man commando team the survivors who were captured were executed under orders of the xxmaj german xxmaj army against xxunk , and xxunk acts of the xxmaj state of xxmaj germany . \n",
       " \n",
       "  xxmaj the xxmaj xxunk xxmaj no . xxunk / xxunk xxunk xxmaj xxunk . xxup xxunk / xxunk , xxmaj xxunk xxup xxunk , 18 xxmaj xxunk xxunk , ( xxunk ) xxmaj xxunk xxmaj hitler ; xxmaj translation of xxmaj document no . xxup xxunk , xxmaj office of xxup u.s. xxmaj chief of xxmaj xxunk , xxunk true copy xxmaj xxunk xxmaj major , xxunk xxup xxunk xxunk xxmaj march xxunk , xxunk , xxunk at the xxup u.s. xxmaj national xxmaj xxunk . \n",
       " \n",
       "  xxmaj the xxup xxunk xxmaj society xxunk xxunk xxmaj xxunk xxmaj xxunk . , xxunk xxunk , xxup xxunk xxunk\n",
       "y: CategoryList\n",
       "positive,positive,positive,positive,positive\n",
       "Path: /home/pranav/.fastai/data/imdb_sample"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "??TextList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movie_reviews.train.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 3, 2: 1, 3: 2, 4: 2, 5: 1})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Counter _> creates dictionary of frquencies\n",
    "c = Counter([1,1,1,2,3,4,4,5,3])\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing values of amtrix\n",
    "# Coodinat wise_> row , col , val\n",
    "# Compressed Sparse row method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the document-term matrix in CSR format\n",
    "# i.e. return (values, column_indices, row_pointer)\n",
    "def get_ter_doc_mat(text_list, n_terms):\n",
    "    \n",
    "    # inputs:\n",
    "    #    text_list, a TextList object\n",
    "    #    n_terms, the number of tokens in our IMDb vocabulary\n",
    "    \n",
    "    # output: \n",
    "    #    the CSR format sparse representation of the document-term matrix in the form of a\n",
    "    #    scipy.sparse.csr.csr_matrix object\n",
    "\n",
    "    \n",
    "    # initialize arrays\n",
    "    values = []\n",
    "    column_indices = []\n",
    "    row_pointer = []\n",
    "    row_pointer.append(0)\n",
    "\n",
    "    # from the TextList object\n",
    "    for _, doc in enumerate(text_list):\n",
    "        feature_counter = Counter(doc.data)\n",
    "        column_indices.extend(feature_counter.keys())\n",
    "        values.extend(feature_counter.values())\n",
    "        # Tack on N (number of nonzero elements in the matrix) to the end of the row_pointer array\n",
    "        row_pointer.append(len(values))\n",
    "        \n",
    "    return scipy.sparse.csr_matrix((values, column_indices, row_pointer),\n",
    "                                   shape=(len(row_pointer) - 1, n_terms),\n",
    "                                   dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 58.2 ms, sys: 4.3 ms, total: 62.5 ms\n",
      "Wall time: 58.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "val_term_doc = get_ter_doc_mat(movie_reviews.valid.x, len(movie_reviews.vocab.itos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10x10 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 47 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_term_doc[:10, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_term_doc = get_ter_doc_mat(movie_reviews.train.x , len(movie_reviews.vocab.itos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 6008)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_term_doc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 6008)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_term_doc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<200x6008 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 27848 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_term_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x6008 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 81 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_term_doc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'add_test',\n",
       " 'add_test_folder',\n",
       " 'databunch',\n",
       " 'filter_by_func',\n",
       " 'get_processors',\n",
       " 'label_const',\n",
       " 'label_empty',\n",
       " 'label_from_df',\n",
       " 'label_from_folder',\n",
       " 'label_from_func',\n",
       " 'label_from_list',\n",
       " 'label_from_lists',\n",
       " 'label_from_re',\n",
       " 'lists',\n",
       " 'load_empty',\n",
       " 'load_state',\n",
       " 'path',\n",
       " 'process',\n",
       " 'test',\n",
       " 'train',\n",
       " 'transform',\n",
       " 'transform_y',\n",
       " 'valid']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(movie_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative', 'positive']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.y.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_term_doc\n",
    "y = movie_reviews.train.y\n",
    "val_y = movie_reviews.valid.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'c',\n",
       " 'databunch',\n",
       " 'export',\n",
       " 'filter_by_func',\n",
       " 'get_state',\n",
       " 'item',\n",
       " 'load_empty',\n",
       " 'load_state',\n",
       " 'new',\n",
       " 'predict',\n",
       " 'process',\n",
       " 'set_item',\n",
       " 'tfm_y',\n",
       " 'tfmargs',\n",
       " 'tfmargs_y',\n",
       " 'tfms',\n",
       " 'tfms_y',\n",
       " 'to_csv',\n",
       " 'to_df',\n",
       " 'transform',\n",
       " 'transform_y',\n",
       " 'x',\n",
       " 'y']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(movie_reviews.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'negative': 0, 'positive': 1}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.train.y.c2i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = y.c2i['positive']\n",
    "negative = y.c2i['negative']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = movie_reviews.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = np.squeeze(np.asarray(X[y.items==positive].sum(0)))\n",
    "p0 = np.squeeze(np.asarray(X[y.items==negative].sum(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.stoi['love']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1[142]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p0[142]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "P1 = (p1 + 1)/((y.items==positive).sum()+ 1)\n",
    "P0 = (p0 + 1)/((y.items==negative).sum()+ 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the class likelihood ratios, we can define a **log-count ratio** $R_{t}$ for each token $t$ as\n",
    "### $ R_{t} = \\text{log} \\frac{L(t|+)}  {L(t|-)}$\n",
    "#### The `log-count ratio` ranks tokens by their relative affinities for positive and negative reviews\n",
    "#### We observe that\n",
    "* $R_{t} \\gt 0$ means `positive` reviews are more likely to contain this token \n",
    "* $R_{t} \\lt 0$ means `negative` reviews are more likely to contain this token \n",
    "* $R_{t} = 0$ indicates the token $t$ has equal likelihood to appear in  `positive` and `negative` reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.015487,  0.084839,  0.      ,  0.084839, ...,  1.471133, -1.301455, -1.301455, -1.301455])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = np.log(P1/P0); r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tokens = 10\n",
    "highest_R = np.argpartition(r, -n_tokens)[-n_tokens:] # positive\n",
    "lowest_R = np.argpartition(r, n_tokens)[:n_tokens]    # negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1723, 1662, 1666, 1212, 1143, 1529, 1386, 1620, 1358,  795])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highest_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.08505123261815539"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.log((y.items==positive).mean()  / (y.items==negative).mean()); b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = (val_term_doc @ r + b) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.645"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pred ==val_y.items).mean()  ## accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now using full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.IMDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/pranav/.fastai/data/imdb/train'),\n",
       " PosixPath('/home/pranav/.fastai/data/imdb/tmp_clas'),\n",
       " PosixPath('/home/pranav/.fastai/data/imdb/imdb.vocab'),\n",
       " PosixPath('/home/pranav/.fastai/data/imdb/tmp_lm'),\n",
       " PosixPath('/home/pranav/.fastai/data/imdb/README'),\n",
       " PosixPath('/home/pranav/.fastai/data/imdb/test'),\n",
       " PosixPath('/home/pranav/.fastai/data/imdb/unsup')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/pranav/.fastai/data/imdb/train/unsupBow.feat'),\n",
       " PosixPath('/home/pranav/.fastai/data/imdb/train/labeledBow.feat'),\n",
       " PosixPath('/home/pranav/.fastai/data/imdb/train/neg'),\n",
       " PosixPath('/home/pranav/.fastai/data/imdb/train/pos')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(path/'train').ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failure count is 0\n",
      "\n",
      "CPU times: user 25 s, sys: 10.6 s, total: 35.6 s\n",
      "Wall time: 10min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# throws `BrokenProcessPool' Error sometimes. Keep trying `till it works!\n",
    "count = 0\n",
    "error = True\n",
    "while error:\n",
    "    try: \n",
    "        # Preprocessing steps\n",
    "        reviews_full = (TextList.from_folder(path)\n",
    "             #  Make a `TextList` object that is a list of `WindowsPath` objects, \n",
    "             #     each of which contains the full path to one of the data files.\n",
    "             .split_by_folder(valid='test')\n",
    "             # Generate a `LabelLists` object that splits files by training and validation folders\n",
    "             # Note: .label_from_folder in next line causes the `BrokenProcessPool` error\n",
    "             .label_from_folder(classes=['neg', 'pos']))\n",
    "             # Create a `CategoryLists` object which contains the data and\n",
    "             #   its labels that are derived from folder names\n",
    "        error = False\n",
    "        print(f'failure count is {count}\\n')    \n",
    "    except: # catch *all* exceptions\n",
    "        # accumulate failure count\n",
    "        count = count + 1\n",
    "        print(f'failure count is {count}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = reviews_full.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.38 s, sys: 128 ms, total: 5.51 s\n",
      "Wall time: 6.68 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "valid_doc_term = get_ter_doc_mat(reviews_full.valid.x, len(reviews_full.vocab.itos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc_term = get_ter_doc_mat(reviews_full.train.x, len(reviews_full.vocab.itos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving these doc_term matrices\n",
    "scipy.sparse.save_npz('valid_doc_term.npz' , valid_doc_term)\n",
    "scipy.sparse.save_npz('train_doc_term.npz' , train_doc_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive bayes on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_doc_term\n",
    "y = reviews_full.train.y\n",
    "\n",
    "val_y = reviews_full.valid.y.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25000x38456 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3716265 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = y.c2i['pos']\n",
    "negative = y.c2i['neg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "C0 = np.squeeze(np.asarray(x[y.items==negative].sum(0)))\n",
    "C1 = np.squeeze(np.asarray(x[y.items==positive].sum(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1 = (C1+1) / ((y.items==positive).sum() + 1)\n",
    "L0 = (C0+1) / ((y.items==negative).sum() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.066783, 0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      , 0.      ])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = np.log(L1/L0); R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.log((y.items==positive).mean()  / (y.items==negative).mean()); b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, ..., False,  True, False, False])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = (valid_doc_term @ R + b) > 0 ; predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8084"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(predictions == val_y).mean() #80 % accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25000x38456 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3716265 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Binarized Naive bayes\n",
    "\n",
    "x= train_doc_term.sign()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "C0 = np.squeeze(np.asarray(x[y.items==negative].sum(0)))\n",
    "C1 = np.squeeze(np.asarray(x[y.items==positive].sum(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1 = (C1+1) / ((y.items==positive).sum() + 1)\n",
    "L0 = (C0+1) / ((y.items==negative).sum() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = np.log(L1/L0)\n",
    "b = np.log((y.items==positive).mean()  / (y.items==negative).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, ..., False,  True, False, False])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = (valid_doc_term.sign() @ R + b) > 0 ; predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82924"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(predictions == val_y).mean() #82.9 % accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7704"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = LogisticRegression(C= 0.1,dual = False, solver = 'liblinear')\n",
    "m.fit(x.sign() ,y.items.astype(int))\n",
    "preds = m.predict(valid_doc_term)\n",
    "(preds == val_y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
